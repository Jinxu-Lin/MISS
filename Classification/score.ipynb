{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar2'\n",
    "proj_dim = 4096\n",
    "method = 'trak'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index_path = f'./data/{dataset}/idx-train.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(idx_train): 10000\n"
     ]
    }
   ],
   "source": [
    "# Load train index\n",
    "with open(train_index_path, 'rb')  as handle:\n",
    "    idx_train = pickle.load(handle)\n",
    "print(\"len(idx_train):\", len(idx_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lds_mask_array.shape: (256, 10000)\n"
     ]
    }
   ],
   "source": [
    "# load lds subset index\n",
    "mask_array_list = []\n",
    "for i in range(256):\n",
    "    with open(f'./data/{dataset}/lds_val/sub-idx-{i}.pkl', 'rb')  as handle:\n",
    "        sub_idx_train = pickle.load(handle)\n",
    "    mask_array = np.in1d(idx_train, sub_idx_train)\n",
    "    mask_array_list.append(mask_array)\n",
    "lds_mask_array = np.stack(mask_array_list)\n",
    "print(\"lds_mask_array.shape:\", lds_mask_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lds_loss_array.shape: (256, 2000)\n"
     ]
    }
   ],
   "source": [
    "# load lds subset model output\n",
    "loss_array_list = []\n",
    "for i in range(256):\n",
    "    \n",
    "    for seed in [0,1,2]:\n",
    "        with open(f'./saved/models/{dataset}/lds-val/index-{i}-seed-{seed}/test_CE.pkl', 'rb')  as handle:\n",
    "            # -log(p/(1-p))\n",
    "            loss_list = pickle.load(handle)\n",
    "        margins = np.concatenate(loss_list, axis=-1)\n",
    "\n",
    "        if (seed == 0):\n",
    "            loss_array = margins\n",
    "        else:\n",
    "            loss_array += margins\n",
    "\n",
    "        loss_array = loss_array/3\n",
    "\n",
    "    loss_array_list.append(loss_array) \n",
    "\n",
    "lds_loss_array = np.stack(loss_array_list)\n",
    "print(\"lds_loss_array.shape:\", lds_loss_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00688803 0.01962721 0.51917636 ... 0.01619437 0.26889518 0.02676756]\n"
     ]
    }
   ],
   "source": [
    "print(lds_loss_array[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_grad.shape: (3, 10000, 4096)\n"
     ]
    }
   ],
   "source": [
    "# load grad\n",
    "train_grad_list = []\n",
    "for seed in [0,1,2]:\n",
    "    train_grad_seed = np.memmap(\n",
    "        f'./saved/grad/{dataset}/seed-{seed}/train-{proj_dim}.npy', \n",
    "        dtype=np.float32, \n",
    "        mode='r',\n",
    "        shape=(10000, proj_dim)\n",
    "    )\n",
    "    train_grad_list.append(train_grad_seed)\n",
    "train_grad = np.stack(train_grad_list)\n",
    "print(\"train_grad.shape:\", train_grad.shape)\n",
    "train_grad = torch.from_numpy(train_grad).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7249e+01, -1.6733e+01, -1.1416e+01,  ..., -3.8947e+01,\n",
      "          6.3580e+00, -5.0446e+00],\n",
      "        [ 1.4643e+00,  2.5474e+00,  2.6933e-02,  ...,  1.9473e+00,\n",
      "          1.7577e+00,  3.3745e+00],\n",
      "        [-2.8790e-01, -1.4160e+00, -1.0547e+00,  ..., -3.0139e+00,\n",
      "          8.6601e-01, -5.2559e-01],\n",
      "        ...,\n",
      "        [-5.3286e-01, -2.0897e+00, -2.1248e+00,  ..., -4.1665e+00,\n",
      "          1.4464e+00, -1.4421e+00],\n",
      "        [ 6.0728e-01, -1.3522e+01,  8.1734e-01,  ..., -2.7139e+01,\n",
      "          8.4135e-02, -8.3998e+00],\n",
      "        [ 1.3433e+00,  2.6064e+00,  2.2589e-01,  ...,  2.1558e+00,\n",
      "         -3.9850e-01,  2.0823e+00]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(train_grad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_grad.shape: (3, 2000, 4096)\n"
     ]
    }
   ],
   "source": [
    "test_grad_list = []\n",
    "for seed in [0,1,2]:\n",
    "    test_grad_seed = np.memmap(\n",
    "        f'./saved/grad/{dataset}/seed-{seed}/test-{proj_dim}.npy', \n",
    "        dtype=np.float32, \n",
    "        mode='r',\n",
    "        shape=(2000, proj_dim)\n",
    "    )\n",
    "    test_grad_list.append(test_grad_seed)\n",
    "test_grad = np.stack(test_grad_list)\n",
    "print(\"test_grad.shape:\", test_grad.shape)\n",
    "test_grad = torch.from_numpy(test_grad).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_error.shape: (10000,)\n",
      "train_error_diag.shape: (10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "# load training set error\n",
    "train_error_list = []\n",
    "\n",
    "    \n",
    "for seed in [0,1,2]:\n",
    "    with open(f'./saved/models/{dataset}/origin/seed-{seed}/train_error.pkl', 'rb')  as handle:\n",
    "        # 1-p\n",
    "        error_list = pickle.load(handle)\n",
    "    error_array = np.concatenate(error_list, axis=-1)\n",
    "\n",
    "    if (seed == 0):\n",
    "        train_error = error_array\n",
    "    else:\n",
    "        train_error += error_array\n",
    "\n",
    "train_error = train_error/3\n",
    "print(\"train_error.shape:\", train_error.shape)\n",
    "\n",
    "train_error_diag = np.diag(train_error)\n",
    "print(\"train_error_diag.shape:\", train_error_diag.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the score\n",
    "lds_list = []\n",
    "lamb_list = [\n",
    "        1e-2, 2e-2, 5e-2,\n",
    "        1e-1, 2e-1, 5e-1,\n",
    "        1e0, 2e0, 5e0,\n",
    "        1e1, 2e1, 5e1,\n",
    "        1e2, 2e2, 5e2,\n",
    "        1e3, 2e3, 5e3, \n",
    "        1e4, 2e4, 5e4, \n",
    "        1e5, 2e5, 5e5, \n",
    "        1e6, 2e6, 5e6, \n",
    "    ]\n",
    "\n",
    "rs_list = []\n",
    "ps_list = []\n",
    "best_scores = None\n",
    "best_lds = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.003 (avg p value 0.495328)\n",
      "Correlation: -0.003 (avg p value 0.495328)\n",
      "Correlation: -0.003 (avg p value 0.495328)\n",
      "Correlation: -0.003 (avg p value 0.495208)\n",
      "Correlation: -0.003 (avg p value 0.495177)\n",
      "Correlation: -0.003 (avg p value 0.495132)\n",
      "Correlation: -0.003 (avg p value 0.495458)\n",
      "Correlation: -0.003 (avg p value 0.495260)\n",
      "Correlation: -0.003 (avg p value 0.495212)\n",
      "Correlation: -0.003 (avg p value 0.495535)\n",
      "Correlation: -0.003 (avg p value 0.495224)\n",
      "Correlation: -0.003 (avg p value 0.495238)\n",
      "Correlation: -0.003 (avg p value 0.495324)\n",
      "Correlation: -0.003 (avg p value 0.495252)\n",
      "Correlation: -0.003 (avg p value 0.496218)\n",
      "Correlation: -0.003 (avg p value 0.497177)\n",
      "Correlation: -0.003 (avg p value 0.498108)\n",
      "Correlation: -0.003 (avg p value 0.500973)\n",
      "Correlation: -0.002 (avg p value 0.502486)\n",
      "Correlation: -0.002 (avg p value 0.502870)\n",
      "Correlation: -0.002 (avg p value 0.500195)\n",
      "Correlation: -0.002 (avg p value 0.499914)\n",
      "Correlation: -0.002 (avg p value 0.501630)\n",
      "Correlation: -0.002 (avg p value 0.500173)\n",
      "Correlation: -0.002 (avg p value 0.499155)\n",
      "Correlation: -0.001 (avg p value 0.498979)\n",
      "Correlation: -0.001 (avg p value 0.494325)\n",
      "best_lds: -0.001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for lamb in lamb_list:\n",
    "\n",
    "    scores_list = []\n",
    "\n",
    "    for seed in [0,1,2]:\n",
    "\n",
    "        train_grad_seed = train_grad[seed]\n",
    "        test_grad_seed = test_grad[seed]\n",
    "        kernel = train_grad_seed.T@train_grad_seed\n",
    "        \n",
    "        kernel_ = kernel + lamb*torch.eye(kernel.shape[0]).cuda()\n",
    "        kernel_ = torch.linalg.inv(kernel_)  \n",
    "\n",
    "        if method == 'trak':\n",
    "            scores_seed = test_grad_seed@((train_grad_seed@kernel_).T)\n",
    "            \n",
    "        scores_seed = scores_seed.cpu().numpy()\n",
    "        scores_list.append(scores_seed)\n",
    "    \n",
    "    scores = np.stack(scores_list)\n",
    "    scores = scores.mean(axis=0)\n",
    "    scores = scores@train_error_diag\n",
    "\n",
    "    margins = lds_loss_array\n",
    "    infl_est_ = -scores\n",
    "    preds = lds_mask_array @ infl_est_.T\n",
    "\n",
    "    # compute lds\n",
    "    rs = []\n",
    "    ps = []\n",
    "    for ind in range(2000):\n",
    "        r, p = spearmanr(preds[:, ind], margins[:, ind])\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "    rs, ps = np.array(rs), np.array(ps)\n",
    "    print(f'Correlation: {rs.mean():.3f} (avg p value {ps.mean():.6f})')\n",
    "    \n",
    "    rs_list.append(rs.mean())   \n",
    "    ps_list.append(ps.mean())\n",
    "\n",
    "    if rs.mean()>best_lds:\n",
    "        best_scores = scores\n",
    "        best_lds = rs.mean()\n",
    "\n",
    "print(f'best_lds: {best_lds:.3f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
