{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import spearmanr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar10'\n",
    "proj_dim = 4096\n",
    "method = 'trak'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index_path = f'./data/{dataset}/idx-train.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(idx_train): 10000\n"
     ]
    }
   ],
   "source": [
    "# Load train index\n",
    "with open(train_index_path, 'rb')  as handle:\n",
    "    idx_train = pickle.load(handle)\n",
    "print(\"len(idx_train):\", len(idx_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lds_mask_array.shape: (256, 10000)\n"
     ]
    }
   ],
   "source": [
    "# load lds subset index\n",
    "mask_array_list = []\n",
    "for i in range(256):\n",
    "    with open(f'./data/{dataset}/lds-val/sub-idx-{i}.pkl', 'rb')  as handle:\n",
    "        sub_idx_train = pickle.load(handle)\n",
    "    mask_array = np.in1d(idx_train, sub_idx_train)\n",
    "    mask_array_list.append(mask_array)\n",
    "lds_mask_array = np.stack(mask_array_list)\n",
    "print(\"lds_mask_array.shape:\", lds_mask_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lds_loss_array.shape: (256, 2000)\n"
     ]
    }
   ],
   "source": [
    "# load lds subset model output\n",
    "loss_array_list = []\n",
    "for i in range(256):\n",
    "    \n",
    "    for seed in [0,1,2]:\n",
    "        with open(f'./saved/models/{dataset}/lds-val/index-{i}-seed-{seed}/test_CE.pkl', 'rb')  as handle:\n",
    "            # -log(p/(1-p))\n",
    "            loss_list = pickle.load(handle)\n",
    "        margins = np.concatenate(loss_list, axis=-1)\n",
    "\n",
    "        if (seed == 0):\n",
    "            loss_array = margins\n",
    "        else:\n",
    "            loss_array += margins\n",
    "\n",
    "        loss_array = loss_array/3\n",
    "\n",
    "    loss_array_list.append(loss_array) \n",
    "\n",
    "lds_loss_array = np.stack(loss_array_list)\n",
    "print(\"lds_loss_array.shape:\", lds_loss_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00534243 0.0128518  0.743119   ... 0.00122539 0.14862019 0.01446892]\n"
     ]
    }
   ],
   "source": [
    "print(lds_loss_array[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_grad.shape: (3, 50000, 4096)\n"
     ]
    }
   ],
   "source": [
    "# load grad\n",
    "train_grad_list = []\n",
    "for seed in [0,1,2]:\n",
    "    train_grad_seed = np.memmap(\n",
    "        f'./saved/grad/{dataset}/seed-{seed}/train-{proj_dim}.npy', \n",
    "        dtype=np.float32, \n",
    "        mode='r',\n",
    "        shape=(50000, proj_dim)\n",
    "    )\n",
    "    train_grad_list.append(train_grad_seed)\n",
    "train_grad = np.stack(train_grad_list)\n",
    "print(\"train_grad.shape:\", train_grad.shape)\n",
    "train_grad = torch.from_numpy(train_grad).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2.6007,   -4.9872,   -1.1759,  ...,    1.9265,    3.2511,\n",
      "            0.9981],\n",
      "        [  10.2037,   -3.1205,   38.7742,  ...,   -0.7167,   36.7600,\n",
      "           25.9978],\n",
      "        [   0.3561,   -0.4147,    0.8392,  ...,   -1.5259,    0.9411,\n",
      "            1.0625],\n",
      "        ...,\n",
      "        [ -33.7301,  -67.1206,   -2.4379,  ...,  -15.1601,   35.2279,\n",
      "           19.3252],\n",
      "        [ -69.9211,  122.3050, -187.9740,  ...,   70.7942,   -9.9055,\n",
      "          -16.9099],\n",
      "        [   0.3797,   -5.9832,   -2.9847,  ...,   12.1952,   -8.8484,\n",
      "            6.3969]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(train_grad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_grad.shape: (3, 10000, 4096)\n"
     ]
    }
   ],
   "source": [
    "test_grad_list = []\n",
    "for seed in [0,1,2]:\n",
    "    test_grad_seed = np.memmap(\n",
    "        f'./saved/grad/{dataset}/seed-{seed}/test-{proj_dim}.npy', \n",
    "        dtype=np.float32, \n",
    "        mode='r',\n",
    "        shape=(10000, proj_dim)\n",
    "    )\n",
    "    test_grad_list.append(test_grad_seed)\n",
    "test_grad = np.stack(test_grad_list)\n",
    "print(\"test_grad.shape:\", test_grad.shape)\n",
    "test_grad = torch.from_numpy(test_grad).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_error.shape: (10000,)\n",
      "train_error_diag.shape: (10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "# load training set error\n",
    "train_error_list = []\n",
    "\n",
    "    \n",
    "for seed in [0,1,2]:\n",
    "    with open(f'./saved/models/{dataset}/origin/seed-{seed}/train_error.pkl', 'rb')  as handle:\n",
    "        # 1-p\n",
    "        error_list = pickle.load(handle)\n",
    "    error_array = np.concatenate(error_list, axis=-1)\n",
    "\n",
    "    if (seed == 0):\n",
    "        train_error = error_array\n",
    "    else:\n",
    "        train_error += error_array\n",
    "\n",
    "train_error = train_error/3\n",
    "print(\"train_error.shape:\", train_error.shape)\n",
    "\n",
    "train_error_diag = np.diag(train_error)\n",
    "print(\"train_error_diag.shape:\", train_error_diag.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the score\n",
    "lds_list = []\n",
    "lamb_list = [\n",
    "        1e-2, 2e-2, 5e-2,\n",
    "        1e-1, 2e-1, 5e-1,\n",
    "        1e0, 2e0, 5e0,\n",
    "        1e1, 2e1, 5e1,\n",
    "        1e2, 2e2, 5e2,\n",
    "        1e3, 2e3, 5e3, \n",
    "        1e4, 2e4, 5e4, \n",
    "        1e5, 2e5, 5e5, \n",
    "        1e6, 2e6, 5e6, \n",
    "    ]\n",
    "\n",
    "rs_list = []\n",
    "ps_list = []\n",
    "best_scores = None\n",
    "best_lds = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6011, 50000])\n",
      "torch.Size([6011, 10000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2710358/233794002.py:5: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449229234/work/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  masks = torch.as_tensor(np.load(masks_path, mmap_mode='r')).float()\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# corr = eval_correlations(scores, '.')\n",
    "tmp_path = './tmp'\n",
    "masks_path = Path(tmp_path).joinpath('mask.npy')\n",
    "masks = torch.as_tensor(np.load(masks_path, mmap_mode='r')).float()\n",
    "print(masks.shape)\n",
    "\n",
    "margins_path = Path(tmp_path).joinpath('val_margins.npy')\n",
    "margins = torch.as_tensor(np.load(margins_path, mmap_mode='r'))\n",
    "print(margins.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 791.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 791.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 781.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 792.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 800.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 805.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 790.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 780.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 783.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487321)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 792.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487319)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 788.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487320)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 790.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 801.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 791.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487318)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 800.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487324)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 790.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487323)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 782.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 798.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487324)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 806.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487319)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 787.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 809.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487325)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 792.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487328)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 789.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.487332)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 779.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.000 (avg p value 0.487395)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 777.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.000 (avg p value 0.487569)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 781.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.000 (avg p value 0.487662)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:12, 784.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.000 (avg p value 0.487761)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for lamb in lamb_list:\n",
    "\n",
    "    scores_list = []\n",
    "\n",
    "    for seed in [0,1,2]:\n",
    "\n",
    "        train_grad_seed = train_grad[seed]\n",
    "        test_grad_seed = test_grad[seed]\n",
    "        kernel = train_grad_seed.T@train_grad_seed\n",
    "        \n",
    "        kernel_ = kernel + lamb*torch.eye(kernel.shape[0]).cuda()\n",
    "        kernel_ = torch.linalg.inv(kernel_)  \n",
    "\n",
    "        if method == 'trak':\n",
    "            scores_seed = test_grad_seed@((train_grad_seed@kernel_).T)\n",
    "            \n",
    "        scores_seed = scores_seed.cpu().numpy()\n",
    "        scores_list.append(scores_seed)\n",
    "    \n",
    "    scores = np.stack(scores_list)\n",
    "    scores = scores.mean(axis=0)\n",
    "    # scores = scores@train_error_diag\n",
    "\n",
    "    val_inds = np.arange(10000)\n",
    "    preds = masks @ scores.T\n",
    "    rs = []\n",
    "    ps = []\n",
    "    for ind, j in tqdm(enumerate(val_inds)):\n",
    "        r, p = spearmanr(preds[:, ind], margins[:, j])\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "    rs, ps = np.array(rs), np.array(ps)\n",
    "    print(f'Correlation: {rs.mean():.3f} (avg p value {ps.mean():.6f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.001 (avg p value 0.496782)\n",
      "Correlation: -0.001 (avg p value 0.496782)\n",
      "Correlation: -0.001 (avg p value 0.496782)\n",
      "Correlation: -0.001 (avg p value 0.496639)\n",
      "Correlation: -0.001 (avg p value 0.497024)\n",
      "Correlation: -0.001 (avg p value 0.496754)\n",
      "Correlation: -0.001 (avg p value 0.496501)\n",
      "Correlation: -0.001 (avg p value 0.496666)\n",
      "Correlation: -0.001 (avg p value 0.496913)\n",
      "Correlation: -0.001 (avg p value 0.496929)\n",
      "Correlation: -0.001 (avg p value 0.496910)\n",
      "Correlation: -0.001 (avg p value 0.496853)\n",
      "Correlation: -0.001 (avg p value 0.497186)\n",
      "Correlation: -0.001 (avg p value 0.497028)\n",
      "Correlation: -0.001 (avg p value 0.496702)\n",
      "Correlation: -0.001 (avg p value 0.496955)\n",
      "Correlation: -0.001 (avg p value 0.497747)\n",
      "Correlation: -0.001 (avg p value 0.499855)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2556313/954094559.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mtrain_error_diag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmargins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlds_loss_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lamb in lamb_list:\n",
    "\n",
    "    scores_list = []\n",
    "\n",
    "    for seed in [0,1,2]:\n",
    "\n",
    "        train_grad_seed = train_grad[seed]\n",
    "        test_grad_seed = test_grad[seed]\n",
    "        kernel = train_grad_seed.T@train_grad_seed\n",
    "        \n",
    "        kernel_ = kernel + lamb*torch.eye(kernel.shape[0]).cuda()\n",
    "        kernel_ = torch.linalg.inv(kernel_)  \n",
    "\n",
    "        if method == 'trak':\n",
    "            scores_seed = test_grad_seed@((train_grad_seed@kernel_).T)\n",
    "            \n",
    "        scores_seed = scores_seed.cpu().numpy()\n",
    "        scores_list.append(scores_seed)\n",
    "    \n",
    "    scores = np.stack(scores_list)\n",
    "    scores = scores.mean(axis=0)\n",
    "    scores = scores@train_error_diag\n",
    "\n",
    "    margins = lds_loss_array\n",
    "    infl_est_ = -scores\n",
    "    preds = lds_mask_array @ infl_est_.T\n",
    "\n",
    "    # compute lds\n",
    "    rs = []\n",
    "    ps = []\n",
    "    for ind in range(2000):\n",
    "        r, p = spearmanr(preds[:, ind], margins[:, ind])\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "    rs, ps = np.array(rs), np.array(ps)\n",
    "    print(f'Correlation: {rs.mean():.3f} (avg p value {ps.mean():.6f})')\n",
    "    \n",
    "    rs_list.append(rs.mean())   \n",
    "    ps_list.append(ps.mean())\n",
    "\n",
    "    if rs.mean()>best_lds:\n",
    "        best_scores = scores\n",
    "        best_lds = rs.mean()\n",
    "\n",
    "print(f'best_lds: {best_lds:.3f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
