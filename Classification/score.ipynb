{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import spearmanr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar10'\n",
    "proj_dim = 4096\n",
    "method = 'trak'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index_path = f'./data/{dataset}/idx-train.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(idx_train): 50000\n"
     ]
    }
   ],
   "source": [
    "# Load train index\n",
    "with open(train_index_path, 'rb')  as handle:\n",
    "    idx_train = pickle.load(handle)\n",
    "print(\"len(idx_train):\", len(idx_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lds_mask_array.shape: (256, 50000)\n"
     ]
    }
   ],
   "source": [
    "# load lds subset index\n",
    "mask_array_list = []\n",
    "for i in range(256):\n",
    "    with open(f'./data/{dataset}/lds-val/sub-idx-{i}.pkl', 'rb')  as handle:\n",
    "        sub_idx_train = pickle.load(handle)\n",
    "    mask_array = np.in1d(idx_train, sub_idx_train)\n",
    "    mask_array_list.append(mask_array)\n",
    "lds_mask_array = np.stack(mask_array_list)\n",
    "print(\"lds_mask_array.shape:\", lds_mask_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './saved/models/cifar10/lds-val/index-0-seed-0/test_CE.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2800752/2828115308.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./saved/models/{dataset}/lds-val/index-{i}-seed-{seed}/test_CE.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0;31m# -log(p/(1-p))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './saved/models/cifar10/lds-val/index-0-seed-0/test_CE.pkl'"
     ]
    }
   ],
   "source": [
    "# load lds subset model output\n",
    "loss_array_list = []\n",
    "for i in range(256):\n",
    "    \n",
    "    for seed in [0,1,2]:\n",
    "        with open(f'./saved/models/{dataset}/lds-val/index-{i}-seed-{seed}/test_CE.pkl', 'rb')  as handle:\n",
    "            # -log(p/(1-p))\n",
    "            loss_list = pickle.load(handle)\n",
    "        margins = np.concatenate(loss_list, axis=-1)\n",
    "\n",
    "        if (seed == 0):\n",
    "            loss_array = margins\n",
    "        else:\n",
    "            loss_array += margins\n",
    "\n",
    "        loss_array = loss_array/3\n",
    "\n",
    "    loss_array_list.append(loss_array) \n",
    "\n",
    "lds_loss_array = np.stack(loss_array_list)\n",
    "print(\"lds_loss_array.shape:\", lds_loss_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00534243 0.0128518  0.743119   ... 0.00122539 0.14862019 0.01446892]\n"
     ]
    }
   ],
   "source": [
    "print(lds_loss_array[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_grad.shape: (3, 50000, 4096)\n"
     ]
    }
   ],
   "source": [
    "# load grad\n",
    "train_grad_list = []\n",
    "for seed in [0,1,2]:\n",
    "    train_grad_seed = np.memmap(\n",
    "        f'./saved/grad/{dataset}/seed-{seed}/train-{proj_dim}.npy', \n",
    "        dtype=np.float32, \n",
    "        mode='r',\n",
    "        shape=(50000, proj_dim)\n",
    "    )\n",
    "    train_grad_list.append(train_grad_seed)\n",
    "train_grad = np.stack(train_grad_list)\n",
    "print(\"train_grad.shape:\", train_grad.shape)\n",
    "train_grad = torch.from_numpy(train_grad).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0654,  0.1253,  0.0296,  ..., -0.0484, -0.0816, -0.0251],\n",
      "        [-0.0406,  0.0124, -0.1541,  ...,  0.0028, -0.1461, -0.1033],\n",
      "        [-0.0350,  0.0408, -0.0825,  ...,  0.1501, -0.0925, -0.1045],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0916, -0.1133,  ...,  0.1811, -0.0785, -0.0799],\n",
      "        [-0.0235, -0.2449, -0.0227,  ..., -0.0476,  0.2568,  0.1992],\n",
      "        [-0.0285, -0.2566, -0.0363,  ..., -0.0409,  0.0697,  0.0336]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(train_grad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_grad.shape: (3, 10000, 4096)\n"
     ]
    }
   ],
   "source": [
    "test_grad_list = []\n",
    "for seed in [0,1,2]:\n",
    "    test_grad_seed = np.memmap(\n",
    "        f'./saved/grad/{dataset}/seed-{seed}/test-{proj_dim}.npy', \n",
    "        dtype=np.float32, \n",
    "        mode='r',\n",
    "        shape=(10000, proj_dim)\n",
    "    )\n",
    "    test_grad_list.append(test_grad_seed)\n",
    "test_grad = np.stack(test_grad_list)\n",
    "print(\"test_grad.shape:\", test_grad.shape)\n",
    "test_grad = torch.from_numpy(test_grad).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_error.shape: (10000,)\n",
      "train_error_diag.shape: (10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "# load training set error\n",
    "train_error_list = []\n",
    "\n",
    "    \n",
    "for seed in [0,1,2]:\n",
    "    with open(f'./saved/models/{dataset}/origin/seed-{seed}/train_error.pkl', 'rb')  as handle:\n",
    "        # 1-p\n",
    "        error_list = pickle.load(handle)\n",
    "    error_array = np.concatenate(error_list, axis=-1)\n",
    "\n",
    "    if (seed == 0):\n",
    "        train_error = error_array\n",
    "    else:\n",
    "        train_error += error_array\n",
    "\n",
    "train_error = train_error/3\n",
    "print(\"train_error.shape:\", train_error.shape)\n",
    "\n",
    "train_error_diag = np.diag(train_error)\n",
    "print(\"train_error_diag.shape:\", train_error_diag.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the score\n",
    "lds_list = []\n",
    "lamb_list = [\n",
    "        1e-2, 2e-2, 5e-2,\n",
    "        1e-1, 2e-1, 5e-1,\n",
    "        1e0, 2e0, 5e0,\n",
    "        1e1, 2e1, 5e1,\n",
    "        1e2, 2e2, 5e2,\n",
    "        1e3, 2e3, 5e3, \n",
    "        1e4, 2e4, 5e4, \n",
    "        1e5, 2e5, 5e5, \n",
    "        1e6, 2e6, 5e6, \n",
    "    ]\n",
    "\n",
    "rs_list = []\n",
    "ps_list = []\n",
    "best_scores = None\n",
    "best_lds = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6011, 50000])\n",
      "torch.Size([6011, 10000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2800752/233794002.py:5: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449229234/work/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  masks = torch.as_tensor(np.load(masks_path, mmap_mode='r')).float()\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# corr = eval_correlations(scores, '.')\n",
    "tmp_path = './tmp'\n",
    "masks_path = Path(tmp_path).joinpath('mask.npy')\n",
    "masks = torch.as_tensor(np.load(masks_path, mmap_mode='r')).float()\n",
    "print(masks.shape)\n",
    "\n",
    "margins_path = Path(tmp_path).joinpath('val_margins.npy')\n",
    "margins = torch.as_tensor(np.load(margins_path, mmap_mode='r'))\n",
    "print(margins.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:10, 913.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.492682)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:10, 913.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.492686)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:10, 913.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.492685)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:10, 913.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.492690)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:10, 912.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.492683)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:10, 914.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.492692)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:10, 914.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.492686)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:10, 912.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.492680)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:10, 912.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.492706)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:10, 913.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.492879)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:11, 908.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.493193)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:11, 908.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.492116)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:11, 908.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.490235)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:11, 906.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.489506)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:11, 906.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.489628)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:11, 908.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.000 (avg p value 0.490580)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2800752/3219746227.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mval_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/miss/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[0;34m(self, array)\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[0;31m# Wrap Numpy array again in a suitable tensor when done, to support e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[0;31m# `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             return handle_torch_function(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for lamb in lamb_list:\n",
    "\n",
    "    scores_list = []\n",
    "\n",
    "    for seed in [0,1,2]:\n",
    "\n",
    "        train_grad_seed = train_grad[seed]\n",
    "        test_grad_seed = test_grad[seed]\n",
    "        kernel = train_grad_seed.T@train_grad_seed\n",
    "        \n",
    "        kernel_ = kernel + lamb*torch.eye(kernel.shape[0]).cuda()\n",
    "        kernel_ = torch.linalg.inv(kernel_)  \n",
    "\n",
    "        if method == 'trak':\n",
    "            scores_seed = test_grad_seed@((train_grad_seed@kernel_).T)\n",
    "            \n",
    "        scores_seed = scores_seed.cpu().numpy()\n",
    "        scores_list.append(scores_seed)\n",
    "    \n",
    "    scores = np.stack(scores_list)\n",
    "    scores = scores.mean(axis=0)\n",
    "    # scores = scores@train_error_diag\n",
    "\n",
    "    val_inds = np.arange(10000)\n",
    "    preds = masks @ scores.T\n",
    "    rs = []\n",
    "    ps = []\n",
    "    for ind, j in tqdm(enumerate(val_inds)):\n",
    "        r, p = spearmanr(preds[:, ind], margins[:, j])\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "    rs, ps = np.array(rs), np.array(ps)\n",
    "    print(f'Correlation: {rs.mean():.3f} (avg p value {ps.mean():.6f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: -0.001 (avg p value 0.496782)\n",
      "Correlation: -0.001 (avg p value 0.496782)\n",
      "Correlation: -0.001 (avg p value 0.496782)\n",
      "Correlation: -0.001 (avg p value 0.496639)\n",
      "Correlation: -0.001 (avg p value 0.497024)\n",
      "Correlation: -0.001 (avg p value 0.496754)\n",
      "Correlation: -0.001 (avg p value 0.496501)\n",
      "Correlation: -0.001 (avg p value 0.496666)\n",
      "Correlation: -0.001 (avg p value 0.496913)\n",
      "Correlation: -0.001 (avg p value 0.496929)\n",
      "Correlation: -0.001 (avg p value 0.496910)\n",
      "Correlation: -0.001 (avg p value 0.496853)\n",
      "Correlation: -0.001 (avg p value 0.497186)\n",
      "Correlation: -0.001 (avg p value 0.497028)\n",
      "Correlation: -0.001 (avg p value 0.496702)\n",
      "Correlation: -0.001 (avg p value 0.496955)\n",
      "Correlation: -0.001 (avg p value 0.497747)\n",
      "Correlation: -0.001 (avg p value 0.499855)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2556313/954094559.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mtrain_error_diag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmargins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlds_loss_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lamb in lamb_list:\n",
    "\n",
    "    scores_list = []\n",
    "\n",
    "    for seed in [0,1,2]:\n",
    "\n",
    "        train_grad_seed = train_grad[seed]\n",
    "        test_grad_seed = test_grad[seed]\n",
    "        kernel = train_grad_seed.T@train_grad_seed\n",
    "        \n",
    "        kernel_ = kernel + lamb*torch.eye(kernel.shape[0]).cuda()\n",
    "        kernel_ = torch.linalg.inv(kernel_)  \n",
    "\n",
    "        if method == 'trak':\n",
    "            scores_seed = test_grad_seed@((train_grad_seed@kernel_).T)\n",
    "            \n",
    "        scores_seed = scores_seed.cpu().numpy()\n",
    "        scores_list.append(scores_seed)\n",
    "    \n",
    "    scores = np.stack(scores_list)\n",
    "    scores = scores.mean(axis=0)\n",
    "    scores = scores@train_error_diag\n",
    "\n",
    "    margins = lds_loss_array\n",
    "    infl_est_ = -scores\n",
    "    preds = lds_mask_array @ infl_est_.T\n",
    "\n",
    "    # compute lds\n",
    "    rs = []\n",
    "    ps = []\n",
    "    for ind in range(2000):\n",
    "        r, p = spearmanr(preds[:, ind], margins[:, ind])\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "    rs, ps = np.array(rs), np.array(ps)\n",
    "    print(f'Correlation: {rs.mean():.3f} (avg p value {ps.mean():.6f})')\n",
    "    \n",
    "    rs_list.append(rs.mean())   \n",
    "    ps_list.append(ps.mean())\n",
    "\n",
    "    if rs.mean()>best_lds:\n",
    "        best_scores = scores\n",
    "        best_lds = rs.mean()\n",
    "\n",
    "print(f'best_lds: {best_lds:.3f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
