{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinxulin/anaconda3/envs/miss/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import wget\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss, Conv2d, BatchNorm2d\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "import torchvision\n",
    "import warnings\n",
    "import argparse\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet9\n",
    "class Mul(torch.nn.Module):\n",
    "    def __init__(self, weight):\n",
    "        super(Mul, self).__init__()\n",
    "        self.weight = weight\n",
    "    def forward(self, x): return x * self.weight\n",
    "\n",
    "\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class Residual(torch.nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(Residual, self).__init__()\n",
    "        self.module = module\n",
    "    def forward(self, x): return x + self.module(x)\n",
    "\n",
    "\n",
    "def construct_rn9(num_classes=10):\n",
    "    def conv_bn(channels_in, channels_out, kernel_size=3, stride=1, padding=1, groups=1):\n",
    "        return torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(channels_in, channels_out, kernel_size=kernel_size,\n",
    "                            stride=stride, padding=padding, groups=groups, bias=False),\n",
    "                torch.nn.BatchNorm2d(channels_out),\n",
    "                torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "    model = torch.nn.Sequential(\n",
    "        conv_bn(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "        conv_bn(64, 128, kernel_size=5, stride=2, padding=2),\n",
    "        Residual(torch.nn.Sequential(conv_bn(128, 128), conv_bn(128, 128))),\n",
    "        conv_bn(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "        torch.nn.MaxPool2d(2),\n",
    "        Residual(torch.nn.Sequential(conv_bn(256, 256), conv_bn(256, 256))),\n",
    "        conv_bn(256, 128, kernel_size=3, stride=1, padding=0),\n",
    "        torch.nn.AdaptiveMaxPool2d((1, 1)),\n",
    "        Flatten(),\n",
    "        torch.nn.Linear(128, num_classes, bias=False),\n",
    "        Mul(0.2)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dataloader(batch_size=256, num_workers=8, split='train', shuffle=False, augment=True):\n",
    "    if augment:\n",
    "        transforms = torchvision.transforms.Compose(\n",
    "                        [torchvision.transforms.RandomHorizontalFlip(),\n",
    "                         torchvision.transforms.RandomAffine(0),\n",
    "                         torchvision.transforms.ToTensor(),\n",
    "                         torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                                          (0.2023, 0.1994, 0.201))])\n",
    "    else:\n",
    "        transforms = torchvision.transforms.Compose([\n",
    "                         torchvision.transforms.ToTensor(),\n",
    "                         torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                                          (0.2023, 0.1994, 0.201))])\n",
    "        \n",
    "    is_train = (split == 'train')\n",
    "    dataset = torchvision.datasets.CIFAR10(root='/tmp/cifar/',\n",
    "                                           download=True,\n",
    "                                           train=is_train,\n",
    "                                           transform=transforms)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                         shuffle=shuffle,\n",
    "                                         batch_size=batch_size,\n",
    "                                         num_workers=num_workers)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, lr=0.4, epochs=24, momentum=0.9,\n",
    "          weight_decay=5e-4, lr_peak_epoch=5, label_smoothing=0.0, model_id=0):\n",
    "    \n",
    "    opt = SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    iters_per_epoch = len(loader)\n",
    "    # Cyclic LR with single triangle\n",
    "    lr_schedule = np.interp(np.arange((epochs+1) * iters_per_epoch),\n",
    "                            [0, lr_peak_epoch * iters_per_epoch, epochs * iters_per_epoch],\n",
    "                            [0, 1, 0])\n",
    "    scheduler = lr_scheduler.LambdaLR(opt, lr_schedule.__getitem__)\n",
    "    scaler = GradScaler()\n",
    "    loss_fn = CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        print(f\"Epoch {ep} of {epochs}\")\n",
    "        for it, (ims, labs) in enumerate(loader):\n",
    "            ims = ims.cuda()\n",
    "            labs = labs.cuda()\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with autocast():\n",
    "                out = model(ims)\n",
    "                loss = loss_fn(out, labs)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "        if ep in [12, 15, 18, 21, 23]:\n",
    "            torch.save(model.state_dict(), f'./checkpoints/sd_{model_id}_epoch_{ep}.pt')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models..:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 of 24\n",
      "Epoch 1 of 24\n",
      "Epoch 2 of 24\n",
      "Epoch 3 of 24\n",
      "Epoch 4 of 24\n",
      "Epoch 5 of 24\n",
      "Epoch 6 of 24\n",
      "Epoch 7 of 24\n",
      "Epoch 8 of 24\n",
      "Epoch 9 of 24\n",
      "Epoch 10 of 24\n",
      "Epoch 11 of 24\n",
      "Epoch 12 of 24\n",
      "Epoch 13 of 24\n",
      "Epoch 14 of 24\n",
      "Epoch 15 of 24\n",
      "Epoch 16 of 24\n",
      "Epoch 17 of 24\n",
      "Epoch 18 of 24\n",
      "Epoch 19 of 24\n",
      "Epoch 20 of 24\n",
      "Epoch 21 of 24\n",
      "Epoch 22 of 24\n",
      "Epoch 23 of 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models..: 100%|██████████| 1/1 [00:48<00:00, 48.65s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs('./checkpoints', exist_ok=True)\n",
    "loader_for_training = get_dataloader(batch_size=512, split='train', shuffle=True)\n",
    "\n",
    "# you can modify the for loop below to train more models\n",
    "for i in tqdm(range(1), desc='Training models..'):\n",
    "    model = construct_rn9().to(memory_format=torch.channels_last).cuda()\n",
    "    model = train(model, loader_for_training, model_id=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(loader_for_training.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a list of checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ckpt_files = sorted(list(Path('./checkpoints').rglob('*.pt')))\n",
    "ckpts = [torch.load(ckpt, map_location='cpu') for ckpt in ckpt_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = construct_rn9().to(memory_format=torch.channels_last).cuda()\n",
    "model.load_state_dict(ckpts[-1])\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 62.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loader = get_dataloader(split='val', augment=False)\n",
    "print(len(loader.dataset))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_correct, total_num = 0., 0.\n",
    "    for ims, labs in tqdm(loader):\n",
    "        ims = ims.cuda()\n",
    "        labs = labs.cuda()\n",
    "        with autocast():\n",
    "            out = model(ims)\n",
    "            total_correct += out.argmax(1).eq(labs).sum().cpu().item()\n",
    "            total_num += ims.shape[0]\n",
    "\n",
    "    print(f'Accuracy: {total_correct / total_num * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "loader_train = get_dataloader(batch_size=batch_size, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:TRAK:Could not use CudaProjector.\n",
      "Reason: /home/jinxulin/anaconda3/envs/miss/lib/python3.8/site-packages/fast_jl.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZNK3c106SymInt13toSymNodeImplEv\n",
      "ERROR:TRAK:Defaulting to BasicProjector.\n",
      "INFO:STORE:Existing model IDs in /home/jinxulin/MISS/Classification/trak_results: [0, 1, 2, 3, 4]\n",
      "INFO:STORE:Model IDs that have been finalized: [0, 1, 2, 3, 4]\n",
      "INFO:STORE:Existing TRAK scores:\n",
      "INFO:STORE:quickstart: /home/jinxulin/MISS/Classification/trak_results/scores/quickstart.mmap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "from trak import TRAKer\n",
    "print(len(loader_train.dataset))\n",
    "traker = TRAKer(model=model,\n",
    "                task='image_classification',\n",
    "                proj_dim=4096,\n",
    "                train_set_size=len(loader_train.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute TRAK features for train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(ckpts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:02<00:00, 177.89it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n",
      "Finalizing features for all model IDs..:   0%|          | 0/5 [00:00<?, ?it/s]WARNING:TRAK:Model ID 3 already finalized, skipping .finalize_features for it.\n",
      "WARNING:TRAK:Model ID 0 already finalized, skipping .finalize_features for it.\n",
      "WARNING:TRAK:Model ID 4 already finalized, skipping .finalize_features for it.\n",
      "WARNING:TRAK:Model ID 1 already finalized, skipping .finalize_features for it.\n",
      "WARNING:TRAK:Model ID 2 already finalized, skipping .finalize_features for it.\n",
      "Finalizing features for all model IDs..: 100%|██████████| 5/5 [00:00<00:00, 2991.66it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_id, ckpt in enumerate(tqdm(ckpts)):\n",
    "    print(model_id)\n",
    "    traker.load_checkpoint(ckpt, model_id=model_id)\n",
    "    for batch in tqdm(loader_train):\n",
    "        batch = [x.cuda() for x in batch]\n",
    "        traker.featurize(batch=batch, num_samples=batch[0].shape[0])\n",
    "\n",
    "traker.finalize_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:14<00:00, 14.49s/it]\n",
      "Finalizing scores for all model IDs..: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n",
      "INFO:STORE:Saving scores in /home/jinxulin/MISS/Classification/trak_results/scores/quickstart.mmap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10000)\n"
     ]
    }
   ],
   "source": [
    "loader_targets = get_dataloader(batch_size=batch_size, split='val', augment=False)\n",
    "print(len(loader_targets.dataset))\n",
    "for model_id, ckpt in enumerate(tqdm(ckpts)):\n",
    "    traker.start_scoring_checkpoint(exp_name='quickstart',\n",
    "                                    checkpoint=ckpt,\n",
    "                                    model_id=model_id,\n",
    "                                    num_targets=len(loader_targets.dataset))\n",
    "    for batch in loader_targets:\n",
    "        batch = [x.cuda() for x in batch]\n",
    "        traker.score(batch=batch, num_samples=batch[0].shape[0])\n",
    "\n",
    "scores = traker.finalize_scores(exp_name='quickstart')\n",
    "print(scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_correlations(scores, tmp_path):    \n",
    "    # masks_url = 'https://www.dropbox.com/s/x76uyen8ffkjfke/mask.npy?dl=1'\n",
    "    # margins_url = 'https://www.dropbox.com/s/q1dxoxw78ct7c27/val_margins.npy?dl=1'\n",
    "\n",
    "    masks_path = Path(tmp_path).joinpath('mask.npy')\n",
    "    # wget.download(masks_url, out=str(masks_path), bar=None)\n",
    "    # num masks, num train samples\n",
    "    masks = torch.as_tensor(np.load(masks_path, mmap_mode='r')).float()\n",
    "    \n",
    "    margins_path = Path(tmp_path).joinpath('val_margins.npy')\n",
    "    # wget.download(margins_url, out=str(margins_path), bar=None)\n",
    "    # num , num val samples\n",
    "    margins = torch.as_tensor(np.load(margins_path, mmap_mode='r'))\n",
    "\n",
    "    val_inds = np.arange(10_000)\n",
    "    preds = masks @ scores\n",
    "    rs = []\n",
    "    ps = []\n",
    "    for ind, j in tqdm(enumerate(val_inds)):\n",
    "        r, p = spearmanr(preds[:, ind], margins[:, j])\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "    rs, ps = np.array(rs), np.array(ps)\n",
    "    print(f'Correlation: {rs.mean():.3f} (avg p value {ps.mean():.6f})')\n",
    "    return rs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6011, 50000])\n",
      "torch.Size([6011, 10000])\n"
     ]
    }
   ],
   "source": [
    "# corr = eval_correlations(scores, '.')\n",
    "tmp_path = './tmp'\n",
    "masks_path = Path(tmp_path).joinpath('mask.npy')\n",
    "masks = torch.as_tensor(np.load(masks_path, mmap_mode='r')).float()\n",
    "print(masks.shape)\n",
    "\n",
    "margins_path = Path(tmp_path).joinpath('val_margins.npy')\n",
    "margins = torch.as_tensor(np.load(margins_path, mmap_mode='r'))\n",
    "print(margins.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
