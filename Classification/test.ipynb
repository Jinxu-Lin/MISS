{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_505509/1917225526.py:8: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449229234/work/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  train_grad = torch.from_numpy(train_grad).to('cuda')\n"
     ]
    }
   ],
   "source": [
    "train_grad = np.memmap(\n",
    "    '/home/jinxulin/MISS/Classification/saved/grad/cifar10/seed-0/train-4096.npy', \n",
    "    dtype=np.float16, \n",
    "    mode='r',\n",
    "    shape=(50000, 4096)\n",
    ")\n",
    "#  to tensor\n",
    "train_grad = torch.from_numpy(train_grad).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grad = np.memmap(\n",
    "    '/home/jinxulin/MISS/Classification/saved/grad/cifar10/seed-0/test-4096.npy', \n",
    "    dtype=np.float16, \n",
    "    mode='r',\n",
    "    shape=(10000, 4096)\n",
    ")\n",
    "#  to tensor\n",
    "test_grad = torch.from_numpy(test_grad).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = np.memmap(\n",
    "    '/home/jinxulin/MISS/Classification/saved/grad/cifar10/seed-0/error.npy', \n",
    "    dtype=np.float16, \n",
    "    mode='r',\n",
    "    shape=(50000, 1)\n",
    ")\n",
    "#  to tensor\n",
    "train_error = torch.from_numpy(train_error).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6011, 50000])\n",
      "torch.Size([6011, 10000])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# corr = eval_correlations(scores, '.')\n",
    "tmp_path = './tmp'\n",
    "masks_path = Path(tmp_path).joinpath('mask.npy')\n",
    "masks = torch.as_tensor(np.load(masks_path, mmap_mode='r')).float()\n",
    "print(masks.shape)\n",
    "\n",
    "margins_path = Path(tmp_path).joinpath('val_margins.npy')\n",
    "margins = torch.as_tensor(np.load(margins_path, mmap_mode='r'))\n",
    "print(margins.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_xtx(grads: Tensor) -> Tensor:\n",
    "    proj_dim = grads.shape[1]\n",
    "    result = torch.zeros(\n",
    "        proj_dim, proj_dim, dtype=torch.float16, device='cuda'\n",
    "    )\n",
    "    blocks = torch.split(grads, split_size_or_sections=20000, dim=0)\n",
    "\n",
    "    for block in blocks:\n",
    "        result += block.T @ block\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xtx_inv(xtx: torch.Tensor, lambda_reg: float) -> torch.Tensor:\n",
    "    xtx_reg = xtx + lambda_reg * torch.eye(\n",
    "        xtx.size(0), device=xtx.device, dtype=xtx.dtype\n",
    "    )\n",
    "    xtx_inv = torch.linalg.inv(xtx_reg.to(torch.float32))\n",
    "\n",
    "    xtx_inv /= xtx_inv.abs().mean()\n",
    "\n",
    "    return xtx_inv.to(torch.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_x_xtx_inv(grads: torch.Tensor, xtx_inv: torch.Tensor) -> Tensor:\n",
    "\n",
    "    blocks = torch.split(grads, split_size_or_sections=20000, dim=0)\n",
    "    result = torch.empty(\n",
    "        grads.shape[0], xtx_inv.shape[1], dtype=torch.float16, device='cuda'\n",
    "    )\n",
    "\n",
    "    for i, block in enumerate(blocks):\n",
    "        start = i * 20000\n",
    "        end = min(grads.shape[0], (i + 1) * 20000)\n",
    "        result[start:end] = block @ xtx_inv\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xtx_inv_x(grads: torch.Tensor, xtx_inv: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "    blocks = torch.split(grads, split_size_or_sections=20000, dim=0)\n",
    "    result = torch.empty(\n",
    "        grads.shape[0], xtx_inv.shape[1], dtype=torch.float16, device='cuda'\n",
    "    )\n",
    "\n",
    "    for i, block in enumerate(blocks):\n",
    "        start = i * 20000\n",
    "        end = min(grads.shape[0], (i + 1) * 20000)\n",
    "        result[start:end] = block @ xtx_inv\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trak.utils import get_matrix_mult\n",
    "\n",
    "def get_scores(\n",
    "        features: Tensor, target_grads: Tensor, accumulator: Tensor\n",
    "    ) -> Tensor:\n",
    "        train_dim = features.shape[0]\n",
    "        target_dim = target_grads.shape[0]\n",
    "\n",
    "        accumulator += (\n",
    "            get_matrix_mult(features=features, target_grads=target_grads).detach().cpu()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtx = get_xtx(train_grad)\n",
    "\n",
    "# lamba_list = [\n",
    "#         1e0, \n",
    "#         1e1, \n",
    "#         1e2, \n",
    "#         1e3, \n",
    "#         1e4, \n",
    "#         1e5, \n",
    "#         1e6, \n",
    "#     ]\n",
    "\n",
    "# for lamba in lamba_list:\n",
    "#     xtx_inv = get_xtx_inv(xtx, lamba)\n",
    "#     x_xtx_inv = get_x_xtx_inv(train_grad, xtx_inv)\n",
    "#     trak_score = torch.zeros((50000,10000), device='cpu')\n",
    "#     get_scores(xtx_inv, test_grad, accumulator=trak_score)\n",
    "#     trak_score = trak_score * train_error.cpu()\n",
    "\n",
    "#     val_inds = np.arange(10000)\n",
    "#     preds = masks @ trak_score\n",
    "#     rs = []\n",
    "#     ps = []\n",
    "#     for ind, j in tqdm(enumerate(val_inds)):\n",
    "#         r, p = spearmanr(preds[:, ind], margins[:, j])\n",
    "#         rs.append(r)\n",
    "#         ps.append(p)\n",
    "#     rs, ps = np.array(rs), np.array(ps)\n",
    "#     print(f'Correlation: {rs.mean():.3f} (avg p value {ps.mean():.6f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_influence_matrix(xtx_inv, xtx_inv_x, mask):\n",
    "\n",
    "    # Step 3: compute for each subset\n",
    "\n",
    "\n",
    "    # 获取被删除的样本索引（未被掩盖的样本）\n",
    "    subset_indices = torch.nonzero(~mask).squeeze()\n",
    "\n",
    "    # initialize the influence matrix I(S) = (G^T G + λ I)^(-1)\n",
    "    influence_matrix = xtx_inv.clone()\n",
    "\n",
    "    # add the contribution of the subset samples to the influence matrix\n",
    "    for idx in subset_indices:\n",
    "        single_influence = xtx_inv_x[idx].unsqueeze(1)  # i(x_j)，形状为 (p, 1)\n",
    "        influence_matrix += single_influence @ single_influence.T\n",
    "\n",
    "    return influence_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(scores, mask):\n",
    "    deleted_mask = ~mask\n",
    "\n",
    "    # 使用掩码对 scores 进行行加和\n",
    "    prediction_change = scores[:, deleted_mask].sum(dim=1)\n",
    "\n",
    "    return prediction_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(test_grad, num_train_samples, influence_matrix, device,block_size=5000):\n",
    "    # Step 3: 分块计算 test_grad @ intermediate\n",
    "    m, p = test_grad.shape\n",
    "    scores = torch.empty(m, num_train_samples, device=device)\n",
    "\n",
    "    for start in range(0, m, block_size):\n",
    "        end = min(start + block_size, m)\n",
    "        scores[start:end] = test_grad[start:end] @ influence_matrix\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, mask \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(masks):\n\u001b[1;32m     32\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mbool()\n\u001b[0;32m---> 33\u001b[0m     influence_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_influence_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtx_inv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtx_inv_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Step 4: compute G_test * I(S) G^T\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     influence_matrix \u001b[38;5;241m=\u001b[39m influence_matrix \u001b[38;5;241m@\u001b[39m residual\u001b[38;5;241m.\u001b[39mT\n",
      "Cell \u001b[0;32mIn[14], line 15\u001b[0m, in \u001b[0;36mcompute_influence_matrix\u001b[0;34m(xtx_inv, xtx_inv_x, mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m subset_indices:\n\u001b[1;32m     14\u001b[0m     single_influence \u001b[38;5;241m=\u001b[39m xtx_inv_x[idx]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# i(x_j)，形状为 (p, 1)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     influence_matrix \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m single_influence \u001b[38;5;241m@\u001b[39m single_influence\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m influence_matrix\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xtx = get_xtx(train_grad)\n",
    "\n",
    "lamba_list = [\n",
    "        1e0, \n",
    "        1e1, \n",
    "        1e2, \n",
    "        1e3, \n",
    "        1e4, \n",
    "        1e5, \n",
    "        1e6, \n",
    "    ]\n",
    "\n",
    "\n",
    "for lamba in lamba_list:\n",
    "\n",
    "    # Step 1: Compute (G^T G + λ I)^(-1)\n",
    "    xtx = get_xtx(train_grad)\n",
    "    xtx_inv = get_xtx_inv(xtx, lamba)\n",
    "    # Step 2: Compute (G^T G + λ I)^(-1) G\n",
    "    xtx_inv_x = get_xtx_inv_x(train_grad, xtx_inv)\n",
    "\n",
    "    residual = train_grad * train_error\n",
    "\n",
    "    filename = os.path.join('/home/jinxulin/MISS/Classification/saved/', f'preds_matrix_{lamba}.npy')\n",
    "    preds_matrix = np.memmap(filename, \n",
    "        dtype=np.float16, \n",
    "        mode='w+', \n",
    "        shape=(len(masks), test_grad.shape[0])) \n",
    "\n",
    "    # Step 3: compute for Influence Matrix\n",
    "    for i, mask in enumerate(masks):\n",
    "        mask = mask.bool()\n",
    "        influence_matrix = compute_influence_matrix(xtx_inv, xtx_inv_x, mask)\n",
    "    \n",
    "        # Step 4: compute G_test * I(S) G^T\n",
    "        influence_matrix = influence_matrix @ residual.T\n",
    "        scores = compute_scores(test_grad, train_grad.shape[0], influence_matrix, device)\n",
    "        pred = get_preds(scores, mask)\n",
    "        preds_matrix[i] = pred.cpu().numpy()\n",
    "        preds_matrix.flush()\n",
    "\n",
    "        print(f'{i} / {len(masks)}')\n",
    "    \n",
    "    print('preds_matrix finished')\n",
    "    val_inds = np.arange(test_grad.shape[0])\n",
    "    rs, ps = [], []\n",
    "\n",
    "    for ind, j in tqdm(enumerate(val_inds), desc=\"Evaluating Rank Correlation\"):\n",
    "        preds = preds_matrix[:, j].numpy()\n",
    "        r, p = spearmanr(preds, margins[:, j])\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "    \n",
    "    rs, ps = np.array(rs), np.array(ps)\n",
    "    print(f'Correlation: {rs.mean():.3f} (avg p value {ps.mean():.6f})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
